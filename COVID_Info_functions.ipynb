{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run GeoInfo_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import calendar\n",
    "from sodapy import Socrata\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<font color = 'DarkRed'> County Level </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color='Black'> Obtain COVID data </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color='Black'> Obtain COVID data from the Virginia Health Department Website </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>First check if the json file \"VDH-COVID-19-PublicUseDataset-Cases.json\" exists.<br>\n",
    "If it exists and is current then read the file.<br>Otherwise, import the data from the Virginia Health Department Website and save as a json file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_VA_COVID_data(ByPass_Update = False):\n",
    "    VDH_filename = 'data/VDH-COVID-19-PublicUseDataset-Cases.json'\n",
    "    \n",
    "    if os.path.isfile(VDH_filename):\n",
    "        print('Yay! VDH file exists')\n",
    "        # check if file is current\n",
    "        filetime = dt.datetime.fromtimestamp(os.path.getmtime(VDH_filename))\n",
    "        print(\"VDH file was last modified on \", filetime.date())\n",
    "        today = dt.datetime.now().date()\n",
    "        print(\"Today's date is: \", today)\n",
    "        if filetime.date() == today:\n",
    "            print('Yay, VDH file is current!')\n",
    "            COVID_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "        else:\n",
    "            print('VDH file is not current')\n",
    "            if ByPass_Update:\n",
    "                print('Reading existing file without updating')\n",
    "                COVID_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "            else:\n",
    "                COVID_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "                COVID_data_Virginia.sort_values(by = 'report_date', ignore_index = True, inplace = True)\n",
    "                \n",
    "                date = COVID_data_Virginia['report_date'].iloc[-1]\n",
    "                print('Last recorded date on the existing VDH file is ', pd.to_datetime(date, yearfirst = True))\n",
    "            \n",
    "                print('Updating VDH file from the Virginia Health Department Website')\n",
    "                \n",
    "                df = Update_VDH_COVID_Data(date)\n",
    "                mask = COVID_data_Virginia['report_date'] < date\n",
    "                COVID_data_Virginia = pd.concat([COVID_data_Virginia[mask], df], ignore_index = True)\n",
    "                COVID_data_Virginia.to_json(VDH_filename, orient = 'table')\n",
    "    else:\n",
    "        print('VDH file does not exist')\n",
    "        print('Importing VDH file from the Virginia Health Department Website')\n",
    "        COVID_data_Virginia = Import_VDH_COVID_Data()\n",
    "        COVID_data_Virginia.to_json(VDH_filename, orient = 'table')\n",
    "        \n",
    "    COVID_data_Virginia['report_date'] = pd.to_datetime(COVID_data_Virginia['report_date']).dt.strftime('%y/%m/%d')\n",
    "    COVID_data_Virginia['County Code'] = COVID_data_Virginia['fips'].astype(str).str[2:]\n",
    "    COVID_data_Virginia['fips'] = COVID_data_Virginia['fips'].astype(int)\n",
    "\n",
    "    cols = ['total_cases', 'hospitalizations', 'deaths']\n",
    "    COVID_data_Virginia[cols] = COVID_data_Virginia[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # The Thomas Jefferson health district was later renamed Blue Ridge\n",
    "    COVID_data_Virginia['vdh_health_district'] = np.where(COVID_data_Virginia['vdh_health_district'] == 'Thomas Jefferson',\n",
    "                                                          'Blue Ridge', COVID_data_Virginia['vdh_health_district'])\n",
    "\n",
    "    # At one instance there is an error where \"c\" was entered for the vdh_health_district instead of Rappahannock Rapidan\n",
    "    COVID_data_Virginia['vdh_health_district'] = np.where(COVID_data_Virginia['vdh_health_district'] == 'c', \n",
    "                                                          'Rappahannock Rapidan', COVID_data_Virginia['vdh_health_district'])\n",
    "    \n",
    "#     COVID_data_Virginia['locality'] = [(Get_CountyNames_Dict('51'))[x] for x in COVID_data_Virginia['County Code']]\n",
    "    \n",
    "    COVID_data_Virginia.columns = ['Report Date', 'fips', 'County Name', 'Health District', \n",
    "                                   'Total Cases', 'Hospitalizations', 'Deaths', 'County Code']\n",
    "    \n",
    "    return COVID_data_Virginia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Correct for negative data after completion of quality assurance by the state's Department of Health </font>\n",
    "* <font color='royalblue'> Sometimes the total cases, hospitalization, or death decreases after the DH conducts quality assurance to ensure:<br>\n",
    "1) cases are not assigned to the wrong locality as some ZIP codes cross between localities <br>\n",
    "2) multiple positive test results for the same infection in one person are not counted as multiple COVID-19 cases <br>\n",
    "3) the case follows the criteria outlined in a national case surveillance definition by the CDC. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_COVID_data(df, col_list):\n",
    "    VDH_filename = 'data/VDH-COVID-19-PublicUseDataset-Cases_cleaned.json'\n",
    "    df.sort_values(by = ['County Code', 'Report Date'], inplace = True)\n",
    "    date0 = df.iloc[0]['Report Date']\n",
    "    df.set_index(['County Code', 'Report Date'], inplace = True)\n",
    "    df.sort_index(inplace = True)\n",
    "    \n",
    "    def Get_Dates_of_Adjusment(Mask):\n",
    "        try:\n",
    "            Adjusted_dates = (df[Mask].index).tolist()\n",
    "        except KeyError:\n",
    "            Adjusted_dates = []\n",
    "        return Adjusted_dates\n",
    "    \n",
    "    for col in col_list:\n",
    "        new_col = 'New Daily ' + col.replace('Total ', '')\n",
    "        df[new_col] = df.groupby('County Code')[col].diff().fillna(0)\n",
    "\n",
    "        print('Cleaning', col, 'data')\n",
    "        Adjusted_dates = Get_Dates_of_Adjusment(df[new_col] < 0)\n",
    "        iter = 0\n",
    "        for d in Adjusted_dates:\n",
    "            Max_cases = df.loc[d, col]\n",
    "            Mask = df[col] > Max_cases\n",
    "            Ind = df[Mask].loc[(d[0], date0) : d].index\n",
    "            df.loc[Ind, col] = Max_cases\n",
    "            iter += 1\n",
    "            \n",
    "        print(iter, ' entries adjusted')\n",
    "        df[new_col] = df.groupby('County Code')[col].diff().fillna(0).astype('int')\n",
    "    \n",
    "    df.reset_index(inplace = True)\n",
    "    df.to_json(VDH_filename, orient = 'table')\n",
    "    \n",
    "    # Keep track of last full clean\n",
    "    filename = 'data/FullCleaning_Date.txt'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(str(dt.datetime.now().date()))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update_Clean_COVID_data(df_all, col_list):\n",
    "    VDH_filename = 'data/VDH-COVID-19-PublicUseDataset-Cases_cleaned.json'\n",
    "    \n",
    "    df_clean = pd.read_json(VDH_filename, orient = 'table')\n",
    "    last_date = df_clean.iloc[-1]['Report Date']\n",
    "    print('Last recorded date on the existing cleaned VDH file is ', pd.to_datetime(last_date, yearfirst = True))\n",
    "    \n",
    "    df = (df_all[df_all['Report Date'] >= last_date]).copy()\n",
    "    df0 = df_clean[df_clean['Report Date'] < last_date].copy()\n",
    "    df0.drop(['New Daily Cases', 'New Daily Hospitalizations', 'New Daily Deaths'], axis = 1, inplace = True)\n",
    "    \n",
    "    df = pd.concat([df0, df], ignore_index = True)\n",
    "    df.sort_values(by = ['County Code', 'Report Date'], inplace = True)\n",
    "    date0 = df.iloc[0]['Report Date']\n",
    "    df.set_index(['County Code', 'Report Date'], inplace = True)\n",
    "    df.sort_index(inplace = True)\n",
    "    \n",
    "    def Get_Dates_of_Adjusment(Mask):\n",
    "        try:\n",
    "            Adjusted_dates = (df[Mask].index).tolist()\n",
    "        except KeyError:\n",
    "            Adjusted_dates = []\n",
    "        return Adjusted_dates\n",
    "    \n",
    "    for col in col_list:\n",
    "        new_col = 'New Daily ' + col.replace('Total ', '')\n",
    "        df[new_col] = df.groupby('County Code')[col].diff().fillna(0)\n",
    "\n",
    "        print('Cleaning', col, 'data')\n",
    "        Adjusted_dates = Get_Dates_of_Adjusment(df[new_col] < 0)\n",
    "\n",
    "        iter = 0\n",
    "        for d in Adjusted_dates:\n",
    "            Max_cases = df.loc[d, col]\n",
    "            Mask = df[col] > Max_cases\n",
    "            Ind = df[Mask].loc[(d[0], date0) : d].index\n",
    "            df.loc[Ind, col] = Max_cases\n",
    "            iter += 1\n",
    "\n",
    "        print(iter, ' entries adjusted')\n",
    "        df[new_col] = df.groupby('County Code')[col].diff().fillna(0).astype('int')\n",
    "        \n",
    "    df.reset_index(inplace = True)\n",
    "    df.sort_values(by = ['County Code', 'Report Date'], inplace = True)\n",
    "    df.to_json(VDH_filename, orient = 'table')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> First Go through preliminary cleaning </font>\n",
    "* <font color='royalblue'> It looks like after 01/31/2023 deaths and hospitalizations data suddenly dropped by half. <br>\n",
    "Here, I assume that all data before 02/01/2023 were double counted and will divide by half. <br>\n",
    "Next, I correct for sharp peaks where the total increases and then immediately decreases the next day or vice versa. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prelim_Clean_COVID_Data(df_orig):\n",
    "    df = df_orig.copy()\n",
    "    # first correct for the presumed double counting prior to feb 01 2023\n",
    "    for m in ['Hospitalizations', 'Deaths']:\n",
    "        df[m] = np.where(df['Report Date'] < '23/02/01', (df[m]/2).astype(int), df[m])\n",
    "    \n",
    "    # next correct for sharp peaks\n",
    "    df.set_index(['County Code', 'Report Date'], inplace = True)\n",
    "    df.sort_index(inplace = True)\n",
    "    date_last = df.iloc[-1][0]\n",
    "    \n",
    "    col_list = ['Total Cases', 'Hospitalizations', 'Deaths']\n",
    "    for col in col_list:\n",
    "        dcol = 'Diff ' + col\n",
    "        dcol_sum = 'Sum Diff ' + col\n",
    "        df[dcol] = df.groupby(level = 'County Code')[col].diff().fillna(0).astype(int)\n",
    "        df[dcol_sum] = (df.groupby(level = 'County Code', as_index = False)[dcol].rolling(2).sum().\n",
    "                        shift(periods = -1).fillna(0).astype(int).drop('County Code', axis = 1))\n",
    "        mask1 = abs(df[dcol_sum]) < 0.11*abs(df[dcol])\n",
    "        mask2 = df.index.get_level_values('Report Date') != date_last\n",
    "        mask = mask1 & mask2\n",
    "        Nentries = len(df[mask])\n",
    "        if Nentries == 0:\n",
    "            print('No entries to be adjusted for ', col)\n",
    "            continue\n",
    "        df.loc[mask, col] = np.nan\n",
    "        df[col] = (df[col].ffill()).astype(int)\n",
    "        print('{} entries adjusted for {}'.format(Nentries, col))\n",
    "        df.drop(columns = [dcol, dcol_sum], inplace = True)\n",
    "        \n",
    "    df.reset_index(inplace = True)  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Cleaned_VA_COVID_data(ByPass_Update = False):\n",
    "    VDH_filename = 'data/VDH-COVID-19-PublicUseDataset-Cases_cleaned.json'\n",
    "    clean_date_filename = 'data/FullCleaning_Date.txt'\n",
    "\n",
    "    today = dt.datetime.now().date()\n",
    "    print(\"Today's date is: \", today)\n",
    "    \n",
    "    if os.path.isfile(clean_date_filename):\n",
    "        with open(clean_date_filename, 'r') as file:\n",
    "            clean_date_str = file.read()\n",
    "        \n",
    "        try:\n",
    "            clean_date = dt.datetime.strptime(clean_date_str, '%Y-%m-%d').date()\n",
    "            print('last full clean date: ', clean_date)\n",
    "            if (today - clean_date).days < 14:\n",
    "                print('Not due for full cleaning')\n",
    "                full_clean = False\n",
    "            else:\n",
    "                print('Due for full cleaning')\n",
    "                full_clean = True\n",
    "        except:\n",
    "            full_clean = True\n",
    "    else:\n",
    "        full_clean = True\n",
    "    \n",
    "    col_list = ['Total Cases', 'Hospitalizations', 'Deaths']\n",
    "    if full_clean:\n",
    "        print('time for full cleaning')\n",
    "        df = Get_VA_COVID_data(ByPass_Update)\n",
    "        df = Prelim_Clean_COVID_Data(df)\n",
    "        COVID_data_Virginia = Clean_COVID_data(df, col_list)\n",
    "    else:        \n",
    "        if os.path.isfile(VDH_filename):\n",
    "            print('Yay! cleaned VDH file exists')\n",
    "            # check if file is current\n",
    "            filetime = dt.datetime.fromtimestamp(os.path.getmtime(VDH_filename))\n",
    "            print(\"cleaned VDH file was last modified on \", filetime.date())\n",
    "    #         today = dt.datetime.now().date()\n",
    "    #         print(\"Today's date is: \", today)\n",
    "            if filetime.date() == today:\n",
    "                print('Yay, cleaned VDH file is current!')\n",
    "                COVID_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "            else:\n",
    "                print('cleaned VDH file is not current')\n",
    "                if ByPass_Update:\n",
    "                    print('Reading existing file without updating')\n",
    "                    COVID_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "                else:\n",
    "                    print('retrieving VDH file')\n",
    "                    df = Get_VA_COVID_data(ByPass_Update)\n",
    "                    print('Updating Cleaned VDH file')\n",
    "    #                 col_list = ['Total Cases', 'Hospitalizations', 'Deaths']\n",
    "                    COVID_data_Virginia = Update_Clean_COVID_data(df, col_list)\n",
    "        else:\n",
    "            print('cleaned VDH file does not exist')\n",
    "            df = Get_VA_COVID_data(ByPass_Update)\n",
    "            # First go through the preliminary cleaning\n",
    "            df = Prelim_Clean_COVID_Data(df)\n",
    "            COVID_data_Virginia = Clean_COVID_data(df, col_list)\n",
    "        \n",
    "    COVID_data_Virginia['County Code'] = COVID_data_Virginia['County Code'].astype(str)\n",
    "    \n",
    "    COVID_data_Virginia['Hospitalizations Ratio'] = (COVID_data_Virginia['Hospitalizations'].\n",
    "                                                     divide(COVID_data_Virginia['Total Cases'])).replace(np.nan, 0)\n",
    "    COVID_data_Virginia['Deaths Ratio'] = (COVID_data_Virginia['Deaths'].\n",
    "                                           divide(COVID_data_Virginia['Total Cases'])).replace(np.nan, 0)\n",
    "    COVID_data_Virginia['Deaths per Hospitalizations'] = (COVID_data_Virginia['Deaths'].\n",
    "                                                          divide(COVID_data_Virginia['Hospitalizations'])\n",
    "                                                         ).replace(np.nan, 0)\n",
    "        \n",
    "    return COVID_data_Virginia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Vaccine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_VA_COVID_Vaccines_data(ByPass_Update = False):\n",
    "    VDH_filename = 'data/VDH-COVID-19-PublicUseDataset-Vaccines-DosesAdministered.json'\n",
    "    \n",
    "    if os.path.isfile(VDH_filename):\n",
    "        print('Yay! VDH Vaccines Data file exists')\n",
    "        # check if file is current\n",
    "        filetime = dt.datetime.fromtimestamp(os.path.getmtime(VDH_filename))\n",
    "        print(\"VDH Vaccines Data file was last modified on \", filetime.date())\n",
    "        today = dt.datetime.now().date()\n",
    "        print(\"Today's date is: \", today)\n",
    "        if filetime.date() == today:\n",
    "            print('Yay, VDH Vaccines Data file is current!')\n",
    "            Vaccines_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "        else:\n",
    "            print('VDH Vaccines Data file is not current')\n",
    "            if ByPass_Update:\n",
    "                print('Reading existing file without updating')\n",
    "                Vaccines_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "            else:\n",
    "                Vaccines_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "                Vaccines_data_Virginia.dropna(inplace = True)\n",
    "                Vaccines_data_Virginia.sort_values(by = 'administration_date', ignore_index = True, inplace = True)\n",
    "                \n",
    "                date = Vaccines_data_Virginia['administration_date'].iloc[-1]\n",
    "                print('Last recorded date on the existing VDH Vaccines Data file is ', pd.to_datetime(date))\n",
    "            \n",
    "                print('Updating VDH Vaccines Data file from the Virginia Health Department Website')\n",
    "\n",
    "                df = Update_VDH_COVID_Vaccines_Data(date)\n",
    "                mask = Vaccines_data_Virginia['administration_date'] < date\n",
    "                Vaccines_data_Virginia = pd.concat([Vaccines_data_Virginia[mask], df], ignore_index = True)\n",
    "                Vaccines_data_Virginia.to_json(VDH_filename, orient = 'table')\n",
    "    else:\n",
    "        print('VDH Vaccines Data file does not exist')\n",
    "        print('Importing VDH Vaccines Data file from the Virginia Health Department Website')\n",
    "        Vaccines_data_Virginia = Import_VDH_COVID_Vaccines_Data()\n",
    "        Vaccines_data_Virginia.to_json(VDH_filename, orient = 'table')\n",
    "\n",
    "    Vaccines_data_Virginia['administration_date'] = pd.DatetimeIndex(Vaccines_data_Virginia['administration_date'])\n",
    "    Vaccines_data_Virginia['County Code'] = Vaccines_data_Virginia['fips'].astype(str).str[2:]\n",
    "\n",
    "    cols = ['fips', 'dose_number', 'vaccine_doses_administered']\n",
    "    Vaccines_data_Virginia[cols] = Vaccines_data_Virginia[cols].apply(pd.to_numeric, errors='coerce')\n",
    "    Vaccines_data_Virginia.dropna(inplace = True)\n",
    "    \n",
    "    Vaccines_data_Virginia['fips'] = Vaccines_data_Virginia['fips'].astype(int)\n",
    "\n",
    "    return Vaccines_data_Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_VA_COVID_Vaccines_data_By_Age(ByPass_Update = False):\n",
    "    VDH_filename = 'data/VDH-COVID-19-PublicUseDataset-Vaccines-DosesAdministered_By-Age-Group.json'\n",
    "    \n",
    "    if os.path.isfile(VDH_filename):\n",
    "        print('Yay! VDH Vaccines Data file exists')\n",
    "        # check if file is current\n",
    "        filetime = dt.datetime.fromtimestamp(os.path.getmtime(VDH_filename))\n",
    "        print(\"VDH Vaccines Data file was last modified on \", filetime.date())\n",
    "        today = dt.datetime.now().date()\n",
    "        print(\"Today's date is: \", today)\n",
    "        if filetime.date() == today:\n",
    "            print('Yay, VDH Vaccines Data file is current!')\n",
    "            Vaccines_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "            print('Done Reading existing file')\n",
    "        else:\n",
    "            print('VDH Vaccines Data file is not current')\n",
    "            if ByPass_Update:\n",
    "                print('Reading existing file without updating')\n",
    "                Vaccines_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "            else:\n",
    "                Vaccines_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "                Vaccines_data_Virginia.sort_values(by = 'report_date', ignore_index = True, inplace = True)\n",
    "                \n",
    "                date = Vaccines_data_Virginia['report_date'].iloc[-1]\n",
    "                print('Last recorded date on the existing VDH Vaccines Data file is ', pd.to_datetime(date))\n",
    "            \n",
    "                print('Updating VDH Vaccines Data file from the Virginia Health Department Website')\n",
    "                \n",
    "                df = Update_VDH_COVID_Vaccines_By_Age_Data(date)\n",
    "                mask = Vaccines_data_Virginia['report_date'] < date\n",
    "                Vaccines_data_Virginia = pd.concat([Vaccines_data_Virginia[mask], df], ignore_index = True)\n",
    "                Vaccines_data_Virginia.to_json(VDH_filename, orient = 'table')\n",
    "    else:\n",
    "        print('VDH Vaccines Data file does not exist')\n",
    "        print('Importing VDH Vaccines Data file from the Virginia Health Department Website')\n",
    "        Vaccines_data_Virginia = Import_VDH_COVID_Vaccines_By_Age_Data()\n",
    "        Vaccines_data_Virginia.dropna(inplace = True)\n",
    "        Vaccines_data_Virginia.sort_values(by = 'report_date', ignore_index = True, inplace = True)\n",
    "        Vaccines_data_Virginia.to_json(VDH_filename, orient = 'table')\n",
    "\n",
    "    Vaccines_data_Virginia['report_date'] = pd.DatetimeIndex(Vaccines_data_Virginia['report_date'])\n",
    "    Vaccines_data_Virginia['County Code'] = Vaccines_data_Virginia['fips'].astype(str).str[2:]\n",
    "    \n",
    "    Vaccines_data_Virginia.drop(columns=['health_district', 'health_region', 'age_group_type', '_18_vaccination_count'], \n",
    "                                inplace = True)\n",
    "    Vaccines_data_Virginia.rename(columns={\"report_date\": \"Report Date\", \"age_group\": \"Age Group\", \n",
    "                                           \"people_by_vaccination_status_count\": \"Count\"}, \n",
    "                                  inplace = True)\n",
    "\n",
    "    cols = ['fips', 'Count']\n",
    "    Vaccines_data_Virginia[cols] = Vaccines_data_Virginia[cols].apply(pd.to_numeric, errors='coerce')\n",
    "    Vaccines_data_Virginia.dropna(inplace = True)\n",
    "    \n",
    "    Vaccines_data_Virginia['fips'] = Vaccines_data_Virginia['fips'].astype(int)\n",
    "    \n",
    "    return Vaccines_data_Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_VA_COVID_Vaccines_data_By_Sex(ByPass_Update = False):\n",
    "    VDH_filename = 'data/VDH-COVID-19-PublicUseDataset-Vaccines-DosesAdministered_By-Sex.json'\n",
    "    \n",
    "    if os.path.isfile(VDH_filename):\n",
    "        print('Yay! VDH Vaccines Data file exists')\n",
    "        # check if file is current\n",
    "        filetime = dt.datetime.fromtimestamp(os.path.getmtime(VDH_filename))\n",
    "        print(\"VDH Vaccines Data file was last modified on \", filetime.date())\n",
    "        today = dt.datetime.now().date()\n",
    "        print(\"Today's date is: \", today)\n",
    "        if filetime.date() == today:\n",
    "            print('Yay, VDH Vaccines Data file is current!')\n",
    "            Vaccines_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "            print('Done Reading existing file')\n",
    "        else:\n",
    "            print('VDH Vaccines Data file is not current')\n",
    "            if ByPass_Update:\n",
    "                print('Reading existing file without updating')\n",
    "                Vaccines_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "            else:\n",
    "                Vaccines_data_Virginia = pd.read_json(VDH_filename, orient = 'table')\n",
    "                Vaccines_data_Virginia.sort_values(by = 'report_date', ignore_index = True, inplace = True)\n",
    "                \n",
    "                date = Vaccines_data_Virginia['report_date'].iloc[-1]\n",
    "                print('Last recorded date on the existing VDH Vaccines Data file is ', pd.to_datetime(date))\n",
    "            \n",
    "                print('Updating VDH Vaccines Data file from the Virginia Health Department Website')\n",
    "                \n",
    "                df = Update_VDH_COVID_Vaccines_By_Sex_Data(date)\n",
    "                mask = Vaccines_data_Virginia['report_date'] < date\n",
    "                Vaccines_data_Virginia = pd.concat([Vaccines_data_Virginia[mask], df], ignore_index = True)\n",
    "                Vaccines_data_Virginia.to_json(VDH_filename, orient = 'table')\n",
    "    else:\n",
    "        print('VDH Vaccines Data file does not exist')\n",
    "        print('Importing VDH Vaccines Data file from the Virginia Health Department Website')\n",
    "        Vaccines_data_Virginia = Import_VDH_COVID_Vaccines_By_Sex_Data()\n",
    "        Vaccines_data_Virginia.dropna(inplace = True)\n",
    "        Vaccines_data_Virginia.sort_values(by = 'report_date', ignore_index = True, inplace = True)\n",
    "        Vaccines_data_Virginia.to_json(VDH_filename, orient = 'table')\n",
    "\n",
    "    Vaccines_data_Virginia['report_date'] = pd.DatetimeIndex(Vaccines_data_Virginia['report_date'])\n",
    "    Vaccines_data_Virginia['County Code'] = Vaccines_data_Virginia['fips'].astype(str).str[2:]\n",
    "    \n",
    "    Vaccines_data_Virginia.drop(columns=['health_district', 'health_region'], inplace = True)\n",
    "    Vaccines_data_Virginia.rename(columns={\"report_date\": \"Report Date\", \n",
    "                                           \"people_by_vaccination_status_count\": \"Count\", \n",
    "                                           \"locality\": \"County Name\", \n",
    "                                           \"vaccination_status\": \"Vaccination Status\"}, \n",
    "                                  inplace = True)\n",
    "    \n",
    "    Vaccines_data_Virginia['Vaccination Status'] = np.where(Vaccines_data_Virginia['Vaccination Status'] == \n",
    "                                                            \"Booster/ Third Dose\", \"First Booster\", \n",
    "                                                            Vaccines_data_Virginia['Vaccination Status'])\n",
    "\n",
    "    cols = ['fips', 'Count']\n",
    "    Vaccines_data_Virginia[cols] = Vaccines_data_Virginia[cols].apply(pd.to_numeric, errors='coerce')\n",
    "    Vaccines_data_Virginia.dropna(inplace = True)\n",
    "    \n",
    "    Vaccines_data_Virginia['fips'] = Vaccines_data_Virginia['fips'].astype(int)\n",
    "    \n",
    "    return Vaccines_data_Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Counties_Vacc_Summary(State_Code, df):\n",
    "    df_pivot = df.pivot_table(index = ['County Code', 'administration_date'], columns = 'dose_number', \n",
    "                              values = 'vaccine_doses_administered', fill_value = 0, aggfunc = np.sum).astype(int)\n",
    "    df_counties = ((df_pivot.groupby(level = 0).cumsum().add_prefix('people with at least ').add_suffix(' doses')).\n",
    "                   unstack(0).fillna(method='ffill').fillna(0).astype(int)).stack().reset_index()\n",
    "    df_counties = df_counties.rename(columns = {'people with at least 1 doses': 'people with at least 1 dose'})\n",
    "    \n",
    "    col_list = df_counties.loc[:, 'people with at least 1 dose':'people with at least 4 doses'].columns.to_list()\n",
    "    df_counties = Add_Pop_data(State_Code, 'County', df_counties, col_list)\n",
    "    df_counties.sort_values(by = ['administration_date', 'County Code'], inplace = True)\n",
    "    df_counties.set_index('administration_date', inplace = True)\n",
    "    df_counties.index.names = ['Date']\n",
    "    \n",
    "    df_counties['County Name'] = [(Get_CountyNames_Dict('51'))[x] for x in df_counties['County Code']]\n",
    "    \n",
    "    return df_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Counties_Vacc_Stat_Summary(State_Code, df):\n",
    "    df_pivot = df.pivot_table(index = ['County Code', 'Report Date'], columns = 'Vaccination Status', \n",
    "                              values = 'Count', fill_value = 0, aggfunc = np.sum).astype(int)\n",
    "    df0 = df_pivot.rename_axis(None, axis = 1).reset_index()\n",
    "    \n",
    "    df_counties = Prelim_Clean_Vacc_By_Sex_Data(df0)\n",
    "    df_counties = Clean_Vacc_By_Sex_Data(df_counties)\n",
    "    col_list = df_counties.set_index(['County Code', 'Report Date']).columns.to_list()\n",
    "    df_counties = Add_Pop_data(State_Code, 'County', df_counties, col_list)\n",
    "    df_counties.sort_values(by = ['Report Date', 'County Code'], inplace = True)\n",
    "    df_counties.set_index('Report Date', inplace = True)\n",
    "    df_counties.index.names = ['Date']\n",
    "    df_counties['County Name'] = [(Get_CountyNames_Dict('51'))[x] for x in df_counties['County Code']]\n",
    "    \n",
    "    return df_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prelim_Clean_Vacc_By_Sex_Data(df_orig):\n",
    "    df = df_orig.copy()\n",
    "    df.set_index(['County Code', 'Report Date'], inplace = True)\n",
    "    df.sort_index(inplace = True)\n",
    "    \n",
    "    col_list = ['At Least One Dose', 'Fully Vaccinated', 'First Booster', 'Second Booster', \n",
    "                'Immunocompromised Dose', 'Not Reported']\n",
    "    for col in col_list:\n",
    "        dcol = 'Diff ' + col\n",
    "        dcol_sum = 'Sum Diff ' + col\n",
    "        df[dcol] = df.groupby(level = 'County Code')[col].diff().fillna(0).astype(int)\n",
    "        df[dcol_sum] = (df.groupby(level = 'County Code', as_index = False)[dcol].rolling(2).sum().\n",
    "                        shift(periods = -1).fillna(0).astype(int).drop('County Code', axis = 1))\n",
    "        mask = (df[dcol] < 0) & ((df[dcol_sum] >= 0) | (abs(df[dcol_sum]) < 0.05*abs(df[dcol])))\n",
    "        Nentries = len(df[mask])\n",
    "        if Nentries == 0:\n",
    "            print('No entries to be adjusted for ', col)\n",
    "            continue\n",
    "        df.loc[mask, col] = np.nan\n",
    "        df[col] = (df[col].ffill()).astype(int)\n",
    "        print('{} entries adjusted for {}'.format(Nentries, col))\n",
    "        df.drop(columns = [dcol, dcol_sum], inplace = True)\n",
    "        \n",
    "    df.reset_index(inplace = True)  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_Vacc_By_Sex_Data(df_orig):\n",
    "    df = df_orig.copy()\n",
    "    \n",
    "    df.sort_values(by = ['County Code', 'Report Date'], inplace = True)\n",
    "    date0 = df.iloc[0]['Report Date']\n",
    "    df.set_index(['County Code', 'Report Date'], inplace = True)\n",
    "    df.sort_index(inplace = True)\n",
    "    \n",
    "    col_list = df.columns.to_list()\n",
    "    \n",
    "    def Get_Obsolete_Date(df_col):\n",
    "        df_col = df_col.to_frame().reset_index()\n",
    "        df_col[col + ' bool'] = 1 - (df_col[col].astype(bool)).astype(int)\n",
    "        df_bool = df_col.groupby('Report Date')[col + ' bool'].sum()\n",
    "        return df_bool[df_bool == 0].index[-1]\n",
    "    \n",
    "    def Get_Dates_of_Adjusment(Mask):\n",
    "        try:\n",
    "            Adjusted_dates = (df[Mask].index).tolist()\n",
    "        except KeyError:\n",
    "            Adjusted_dates = []\n",
    "        return Adjusted_dates\n",
    "    \n",
    "    for col in col_list:\n",
    "        # First find any obsolete dates. Do not adjust after this date\n",
    "        Obsolete_date = Get_Obsolete_Date(df[col].copy())\n",
    "        \n",
    "        new_col = 'New ' + col\n",
    "        df[new_col] = df.groupby('County Code')[col].diff().fillna(0)\n",
    "\n",
    "        print('Cleaning', col, 'data')\n",
    "        Adjusted_dates_init = Get_Dates_of_Adjusment(df[new_col] < 0)\n",
    "        Adjusted_dates = [date for date in Adjusted_dates_init if date[1] <= Obsolete_date]\n",
    "\n",
    "        iter = 0\n",
    "        for d in Adjusted_dates:\n",
    "            Max_cases = df.loc[d, col]\n",
    "            Mask = df[col] > Max_cases\n",
    "            Ind = df[Mask].loc[(d[0], date0) : d].index\n",
    "            df.loc[Ind, col] = Max_cases\n",
    "            iter += 1\n",
    "\n",
    "        print(iter, ' entries adjusted')\n",
    "        df.drop(columns = [new_col], inplace = True)\n",
    "#         df[new_col] = df.groupby('County Code')[col].diff().fillna(0).astype('int')\n",
    "\n",
    "    df.reset_index(inplace = True)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<font color = 'DarkRed'> Congressional Districts Level </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_CongressionalDistricts_COVID_data(State_Code, df_counties):\n",
    "    CD_Pop = Get_District_County_Pop19(State_Code)\n",
    "    col_list = df_counties.loc[:, 'New Daily Cases':'Deaths per Hospitalizations'].columns.to_list()\n",
    "    df = pd.merge(CD_Pop.drop(columns = ['County Name']), \n",
    "                  df_counties.drop(columns = col_list), \n",
    "                  how = 'inner', on = 'County Code')\n",
    "\n",
    "    df.set_index(['County Code', 'CDistrict'], inplace = True)\n",
    "    \n",
    "    Measures = ['Total Cases', 'Hospitalizations', 'Deaths']\n",
    "    for col in Measures:\n",
    "        m = col.replace('Total ', '')\n",
    "        m = m.replace('Hospitalizations', 'Hosps')\n",
    "        df.loc[:, 'Est ' + m + ' in District'] = df.loc[:, col].multiply(df['Ratio in District'], axis = 'index')\n",
    "        df[col + ' in District'] = df['Est ' + m + ' in District'].round().astype(int)\n",
    "        df['Diff ' + m] = (df.groupby(['County Code', 'Report Date'])[col + ' in District'].transform(sum) - df[col])\n",
    "        df['Frac ' + m] = df['Est ' + m + ' in District']%1\n",
    "        mask = df['Frac ' + m] <= 0.5\n",
    "        df['Frac down ' + m] = df['Frac ' + m]*mask\n",
    "        df['Frac up ' + m] = df['Frac ' + m] + mask\n",
    "        df['isMax down ' + m] = ((df.groupby(['County Code', 'Report Date'])['Frac down ' + m].\n",
    "                                 transform(max) == df['Frac down ' + m]) & (df['Frac down ' + m] != 0.0)).astype(int)\n",
    "        df['isMin up ' + m] = ((df.groupby(['County Code', 'Report Date'])['Frac up ' + m].\n",
    "                               transform(min) == df['Frac up ' + m]) & (df['Frac up ' + m] < 1.0)).astype(int)\n",
    "        df[col + ' in District'] -= (df['isMax down ' + m] + df['isMin up ' + m])*df['Diff ' + m]\n",
    "    \n",
    "        df['Diff ' + m] = (df.groupby(['County Code', 'Report Date'])[col + ' in District'].transform(sum) - df[col])\n",
    "        df['New ' + m + ' in District'] = (df.groupby(['County Code', 'CDistrict'])[col + ' in District']\n",
    "                                          ).diff().fillna(0).astype(int)\n",
    "    \n",
    "        def Get_Locations_to_Adjust(Mask):\n",
    "            try:\n",
    "                adj_locs = (df[Mask].index).tolist()\n",
    "            except KeyError:\n",
    "                adj_locs = []\n",
    "            return adj_locs\n",
    "    \n",
    "        df.reset_index(inplace = True)\n",
    "        df.set_index(['County Code', 'CDistrict', 'Report Date'], inplace = True)\n",
    "        adj_mask = df['New ' + m + ' in District'] < 0\n",
    "        locs_to_adjust = Get_Locations_to_Adjust(adj_mask)\n",
    "\n",
    "        for locs in locs_to_adjust:\n",
    "            county = locs[0]\n",
    "            district = locs[1]\n",
    "            date = locs[2]\n",
    "            dg = df.loc[(county, slice(None), date), :].sort_values(by = 'Ratio in District', ascending = False)\n",
    "            all_districts = dg.index.get_level_values(1).tolist()\n",
    "        \n",
    "            df.loc[locs, col + ' in District'] -= df.loc[locs, 'New ' + m + ' in District']\n",
    "        \n",
    "            for d in all_districts:\n",
    "                if df.loc[(county, d, date), 'New ' + m + ' in District'] >= - df.loc[locs, 'New ' + m + ' in District']:\n",
    "                    df.loc[(county, d, date), col + ' in District'] += df.loc[locs, 'New ' + m + ' in District']\n",
    "                    district2 = d\n",
    "                    break\n",
    "                \n",
    "            mask = (df[col] == df.loc[locs, col]) & (df.index.get_level_values(0) == county)\n",
    "            dates = df[mask].index.get_level_values(2).unique().tolist()\n",
    "            dates.remove(date)\n",
    "        \n",
    "            for d in dates:\n",
    "                df.loc[(county, district, d), col + ' in District'] = df.loc[(county, district, date), col + ' in District']\n",
    "                df.loc[(county, district2, d), col + ' in District'] = df.loc[(county, district2, date), col + ' in District']\n",
    "                        \n",
    "\n",
    "        df['New ' + m + ' in District'] = (df.groupby(['County Code', 'CDistrict'])[col + ' in District']\n",
    "                                          ).diff().fillna(0).astype(int)\n",
    "\n",
    "    df_districts = df.groupby(['CDistrict', 'Report Date']\n",
    "                             )[['Total Cases in District', 'Hospitalizations in District', 'Deaths in District']].sum()\n",
    "    \n",
    "    df_districts.columns = ['Total Cases', 'Hospitalizations', 'Deaths']\n",
    "    df_districts['New Daily Cases'] = df_districts.groupby('CDistrict')['Total Cases'].diff().fillna(0).astype('int')\n",
    "    \n",
    "    df_districts['New Daily Hospitalizations'] = (df_districts.groupby('CDistrict')['Hospitalizations'].\n",
    "                                                  diff().fillna(0).astype('int'))\n",
    "    \n",
    "    df_districts['New Daily Deaths'] = df_districts.groupby('CDistrict')['Deaths'].diff().fillna(0).astype('int')\n",
    "    \n",
    "    df_districts['Hospitalizations Ratio'] = (df_districts['Hospitalizations'].\n",
    "                                              divide(df_districts['Total Cases'])).replace(np.nan, 0)\n",
    "    df_districts['Deaths Ratio'] = (df_districts['Deaths'].divide(df_districts['Total Cases'])).replace(np.nan, 0)\n",
    "    df_districts['Deaths per Hospitalizations'] = (df_districts['Deaths'].\n",
    "                                                   divide(df_districts['Hospitalizations'])).replace(np.nan, 0)\n",
    "    df_districts.reset_index(inplace = True)\n",
    "    \n",
    "    return df_districts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_CongressionalDistricts_COVID_Vaccination_data(State_Code, df_counties):\n",
    "    CD_Pop = Get_District_County_Pop19(State_Code)\n",
    "    col_list = df_counties.loc[:, 'people with at least 1 dose per Pop':].columns.to_list()\n",
    "    df = pd.merge(CD_Pop.drop(columns = ['County Name']), \n",
    "                  df_counties.reset_index().drop(columns = col_list), \n",
    "                  how = 'inner', on = 'County Code')\n",
    "\n",
    "    df.set_index(['County Code', 'CDistrict'], inplace = True)\n",
    "    \n",
    "    Measures = df.loc[:, 'people with at least 1 dose':].columns.to_list()\n",
    "    for col in Measures:\n",
    "        df.loc[:, 'Est ' + col + ' in District'] = df.loc[:, col].multiply(df['Ratio in District'], axis = 'index')\n",
    "        df[col + ' in District'] = df['Est ' + col + ' in District'].round().astype(int)\n",
    "        df['Diff ' + col] = (df.groupby(['County Code', 'Date'])[col + ' in District'].transform(sum) - df[col])\n",
    "        df['Frac ' + col] = df['Est ' + col + ' in District']%1\n",
    "        mask = df['Frac ' + col] <= 0.5\n",
    "        df['Frac down ' + col] = df['Frac ' + col]*mask\n",
    "        df['Frac up ' + col] = df['Frac ' + col] + mask\n",
    "        df['isMax down ' + col] = ((df.groupby(['County Code', 'Date'])['Frac down ' + col].\n",
    "                                    transform(max) == df['Frac down ' + col]) & \n",
    "                                   (df['Frac down ' + col] != 0.0)).astype(int)\n",
    "        df['isMin up ' + col] = ((df.groupby(['County Code', 'Date'])['Frac up ' + col].\n",
    "                                  transform(min) == df['Frac up ' + col]) & \n",
    "                                 (df['Frac up ' + col] < 1.0)).astype(int)\n",
    "        df[col + ' in District'] -= (df['isMax down ' + col] + df['isMin up ' + col])*df['Diff ' + col]\n",
    "    \n",
    "        df['Diff ' + col] = (df.groupby(['County Code', 'Date'])[col + ' in District'].transform(sum) - df[col])\n",
    "        df['New ' + col + ' in District'] = (df.groupby(['County Code', 'CDistrict'])\n",
    "                                             [col + ' in District']).diff().fillna(0).astype(int)\n",
    "    \n",
    "        def Get_Locations_to_Adjust(Mask):\n",
    "            try:\n",
    "                adj_locs = (df[Mask].index).tolist()\n",
    "            except KeyError:\n",
    "                adj_locs = []\n",
    "            return adj_locs\n",
    "    \n",
    "        df.reset_index(inplace = True)\n",
    "        df.set_index(['County Code', 'CDistrict', 'Date'], inplace = True)\n",
    "        adj_mask = df['New ' + col + ' in District'] < 0\n",
    "        locs_to_adjust = Get_Locations_to_Adjust(adj_mask)\n",
    "\n",
    "        for locs in locs_to_adjust:\n",
    "            county = locs[0]\n",
    "            district = locs[1]\n",
    "            date = locs[2]\n",
    "            dg = df.loc[(county, slice(None), date), :].sort_values(by = 'Ratio in District', ascending = False)\n",
    "            all_districts = dg.index.get_level_values(1).tolist()\n",
    "        \n",
    "            df.loc[locs, col + ' in District'] -= df.loc[locs, 'New ' + col + ' in District']\n",
    "        \n",
    "            for d in all_districts:\n",
    "                if df.loc[(county, d, date), 'New ' + col + ' in District'] >= -df.loc[locs, 'New ' + col + ' in District']:\n",
    "                    df.loc[(county, d, date), col + ' in District'] += df.loc[locs, 'New ' + col + ' in District']\n",
    "                    district2 = d\n",
    "                    break\n",
    "                \n",
    "            mask = (df[col] == df.loc[locs, col]) & (df.index.get_level_values(0) == county)\n",
    "            dates = df[mask].index.get_level_values(2).unique().tolist()\n",
    "            dates.remove(date)\n",
    "        \n",
    "            for d in dates:\n",
    "                df.loc[(county, district, d), col + ' in District']=df.loc[(county, district, date), col + ' in District']\n",
    "                df.loc[(county, district2, d), col + ' in District']=df.loc[(county, district2, date), col + ' in District']\n",
    "                        \n",
    "\n",
    "        df['New ' + col + ' in District'] = (df.groupby(['County Code', 'CDistrict'])[col + ' in District']\n",
    "                                            ).diff().fillna(0).astype(int)\n",
    "\n",
    "    cols = [s + ' in District' for s in Measures]\n",
    "    df_districts = df.groupby(['CDistrict', 'Date'])[cols].sum()\n",
    "    df_districts.columns = Measures\n",
    "    df_districts.reset_index(inplace = True)\n",
    "    df_districts = Add_Pop_data(State_Code, 'Congressional District', df_districts, Measures)\n",
    "    df_districts.set_index('Date', inplace = True)\n",
    "    \n",
    "    return df_districts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_CongressionalDistricts_COVID_Vacc_Stat_data(State_Code, df_counties):\n",
    "    CD_Pop = Get_District_County_Pop19(State_Code)\n",
    "    col_list = [col for col in df_counties.columns if ('per Pop' in col) | (col == 'County Name')]\n",
    "    df = pd.merge(CD_Pop.drop(columns = ['County Name']), \n",
    "                  df_counties.reset_index().drop(columns = col_list), \n",
    "                  how = 'inner', on = 'County Code')\n",
    "\n",
    "    df.set_index(['County Code', 'CDistrict'], inplace = True)\n",
    "    \n",
    "    Measures = (df_counties.reset_index().drop(columns = col_list).\n",
    "                set_index(['County Code', 'Date']).columns.to_list())\n",
    "    \n",
    "    def Get_Obsolete_Date(df_col):\n",
    "        df_col = df_col.to_frame().reset_index()\n",
    "        df_col[col + ' bool'] = 1 - (df_col[col].astype(bool)).astype(int)\n",
    "        df_bool = df_col.groupby('Date')[col + ' bool'].sum()\n",
    "        return df_bool[df_bool == 0].index[-1]\n",
    "\n",
    "    for col in Measures:\n",
    "        df.loc[:, 'Est ' + col + ' in District'] = df.loc[:, col].multiply(df['Ratio in District'], axis = 'index')\n",
    "        df[col + ' in District'] = df['Est ' + col + ' in District'].round().astype(int)\n",
    "        df['Diff ' + col] = (df.groupby(['County Code', 'Date'])[col + ' in District'].transform(sum) - df[col])\n",
    "        df['Frac ' + col] = df['Est ' + col + ' in District']%1\n",
    "        mask = df['Frac ' + col] <= 0.5\n",
    "        df['Frac down ' + col] = df['Frac ' + col]*mask\n",
    "        df['Frac up ' + col] = df['Frac ' + col] + mask\n",
    "        df['isMax down ' + col] = ((df.groupby(['County Code', 'Date'])['Frac down ' + col].\n",
    "                                    transform(max) == df['Frac down ' + col]) & \n",
    "                                   (df['Frac down ' + col] != 0.0)).astype(int)\n",
    "        df['isMin up ' + col] = ((df.groupby(['County Code', 'Date'])['Frac up ' + col].\n",
    "                                  transform(min) == df['Frac up ' + col]) & \n",
    "                                 (df['Frac up ' + col] < 1.0)).astype(int)\n",
    "        df[col + ' in District'] -= (df['isMax down ' + col] + df['isMin up ' + col])*df['Diff ' + col]\n",
    "    \n",
    "        df['Diff ' + col] = (df.groupby(['County Code', 'Date'])[col + ' in District'].transform(sum) - df[col])\n",
    "        df['New ' + col + ' in District'] = (df.groupby(['County Code', 'CDistrict'])\n",
    "                                             [col + ' in District']).diff().fillna(0).astype(int)\n",
    "        \n",
    "        def Get_Locations_to_Adjust(Mask):\n",
    "            try:\n",
    "                adj_locs = (df[Mask].index).tolist()\n",
    "            except KeyError:\n",
    "                adj_locs = []\n",
    "            return adj_locs\n",
    "    \n",
    "        df.reset_index(inplace = True)\n",
    "        df.set_index(['County Code', 'CDistrict', 'Date'], inplace = True)\n",
    "        \n",
    "        # First find any obsolete dates. Do not adjust after this date\n",
    "        Obsolete_date = Get_Obsolete_Date(df[col].copy())        \n",
    "        \n",
    "        adj_mask = (df['New ' + col + ' in District'] < 0) & (df.index.get_level_values(2) <= Obsolete_date)\n",
    "        locs_to_adjust = Get_Locations_to_Adjust(adj_mask)\n",
    "\n",
    "        for locs in locs_to_adjust:\n",
    "            county = locs[0]\n",
    "            district = locs[1]\n",
    "            date = locs[2]\n",
    "            dg = df.loc[(county, slice(None), date), :].sort_values(by = 'Ratio in District', ascending = False)\n",
    "            all_districts = dg.index.get_level_values(1).tolist()\n",
    "        \n",
    "            df.loc[locs, col + ' in District'] -= df.loc[locs, 'New ' + col + ' in District']\n",
    "        \n",
    "            for d in all_districts:\n",
    "                if df.loc[(county, d, date), 'New ' + col + ' in District'] >= -df.loc[locs, 'New ' + col + ' in District']:\n",
    "                    df.loc[(county, d, date), col + ' in District'] += df.loc[locs, 'New ' + col + ' in District']\n",
    "                    district2 = d\n",
    "                    break\n",
    "                \n",
    "            mask = (df[col] == df.loc[locs, col]) & (df.index.get_level_values(0) == county)\n",
    "            dates = df[mask].index.get_level_values(2).unique().tolist()\n",
    "            dates.remove(date)\n",
    "        \n",
    "            for d in dates:\n",
    "                df.loc[(county, district, d), col + ' in District']=df.loc[(county, district, date), col + ' in District']\n",
    "                df.loc[(county, district2, d), col + ' in District']=df.loc[(county, district2, date), col + ' in District']\n",
    "                        \n",
    "\n",
    "        df['New ' + col + ' in District'] = (df.groupby(['County Code', 'CDistrict'])[col + ' in District']\n",
    "                                            ).diff().fillna(0).astype(int)\n",
    "\n",
    "    cols = [s + ' in District' for s in Measures]\n",
    "    df_districts = df.groupby(['CDistrict', 'Date'])[cols].sum()\n",
    "    df_districts.columns = Measures\n",
    "    df_districts.reset_index(inplace = True)\n",
    "    df_districts = Add_Pop_data(State_Code, 'Congressional District', df_districts, Measures)\n",
    "    df_districts.set_index('Date', inplace = True)\n",
    "    \n",
    "    return df_districts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>=============================================================</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Per_Pop(State_Code, scope, df, col):\n",
    "    if scope == 'County':\n",
    "        Pop_df = Get_Counties_Pop19(State_Code)\n",
    "    elif scope == 'Congressional District':\n",
    "        Pop_df = Get_Districts_Pop19(State_Code)\n",
    "\n",
    "    return df.loc[:, col]/Pop_df.loc[:, 'Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_Pop_data(State_Code, level, df, col_list):\n",
    "#     print(col_list)\n",
    "    if level == 'County':\n",
    "        Pop_df = Get_Counties_Pop19(State_Code)\n",
    "        df.set_index('County Code', inplace = True)\n",
    "    elif level == 'Congressional District':\n",
    "        Pop_df = Get_Districts_Pop19(State_Code)\n",
    "        df.set_index('CDistrict', inplace = True)\n",
    "    \n",
    "    df.sort_index(inplace = True)\n",
    "    for col1 in col_list:\n",
    "        col2 = col1 + ' per Pop'\n",
    "        df[col2] = df.loc[:, col1]/Pop_df.loc[:, 'Population']\n",
    "        \n",
    "    df.reset_index(inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Monthly_Data(df, sIndex):\n",
    "    df_m = df.copy()\n",
    "\n",
    "    df_m['Report Date'] = pd.to_datetime(df_m['Report Date'], yearfirst = True)\n",
    "    df_m['Year'] = df_m['Report Date'].dt.year\n",
    "    df_m['Month'] = df_m['Report Date'].dt.month\n",
    "    \n",
    "    cols = ['Monthly Cases', 'Monthly Hospitalizations', 'Monthly Deaths']\n",
    "    dcols = {'New Daily Cases': cols[0], 'New Daily Hospitalizations': cols[1], 'New Daily Deaths': cols[2]}\n",
    "    \n",
    "    df_m = df_m.rename(columns = dcols).groupby(['Year', 'Month', sIndex])[cols].sum().reset_index()\n",
    "    \n",
    "    d = dict(enumerate(calendar.month_abbr))\n",
    "    df_m.Month = df_m.Month.map(d)\n",
    "    df_m.Year = df_m.Year.astype(str)\n",
    "    df_m['Date'] = df_m.Year + '-' + df_m.Month\n",
    "    \n",
    "    df_m.set_index(sIndex, inplace = True)\n",
    "    df_m.sort_index(inplace = True)\n",
    " \n",
    "    return df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Weekly_Vacc_Data(df, group, freq):\n",
    "    day_name_dict = {0: 'Mon', 1: 'Tue', 2: 'Wed', 3: 'Thu', 4: 'Fri', 5: 'Sat', 6: 'Sun'}\n",
    "    day_of_the_week = df.index[-1].dayofweek\n",
    "    day = day_name_dict[day_of_the_week]\n",
    "    df_weekly = df.groupby(group).resample(freq + day, closed = 'left').asfreq().reset_index(level = 0, drop = True)\n",
    "    df_weekly.index.names = ['Date']\n",
    "    \n",
    "    return df_weekly.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
